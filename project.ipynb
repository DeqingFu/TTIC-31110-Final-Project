{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'invalid': 'warn', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import editdistance\n",
    "import os\n",
    "import glob\n",
    "from rnn.loader import make_loader, Preprocessor\n",
    "from rnn.model import Seq2Seq\n",
    "from rnn.model import LinearND \n",
    "from rnn.model import Attention\n",
    "import matplotlib.pyplot as plt\n",
    "np.seterr(divide='ignore') # masks log(0) errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wer(results):\n",
    "    \"\"\"\n",
    "    Compute the word-error-rate (WER).\n",
    "    \"\"\"\n",
    "    dist = 0.\n",
    "    for label, pred in results:\n",
    "        dist += editdistance.eval(label, pred)\n",
    "    total = sum(len(label) for label, _ in results)\n",
    "    return dist / total\n",
    "\n",
    "def train(model, optimizer, ldr):\n",
    "    \"\"\"\n",
    "    Train the model for an epoch (one pass over the training data)\n",
    "    ----\n",
    "    model: Seq2Seq model instance\n",
    "    optimizer: torch.nn optimizer instance\n",
    "    ldr: data loader instance\n",
    "    ----\n",
    "    Returns the average loss over an epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    model.scheduled_sampling = model.sample_prob != 0\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for ii, (inputs, labels) in enumerate(ldr):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = model.collate(inputs, labels)\n",
    "        loss = model.loss(x, y)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())\n",
    "        \n",
    "    return np.nanmean(losses)\n",
    "\n",
    "def evaluate(model, ldr, preproc, store_prediction=False, print_prediction=False):\n",
    "    \"\"\"\n",
    "    Evaluate the model (on either dev or test).\n",
    "    ----\n",
    "    model: Seq2Seq model instance\n",
    "    ldr: data loader instance\n",
    "    preproc: preprocessor instance\n",
    "    ----\n",
    "    Returns the average loss and wer on a given dataset\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.scheduled_sampling = False\n",
    "    \n",
    "    losses, hyps, refs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in ldr:\n",
    "            x, y = model.collate(inputs, labels)\n",
    "            # get loss\n",
    "            loss = model.loss(x, y)\n",
    "            losses.append(loss.data.item())\n",
    "            # get predictions\n",
    "            pred = model.infer(x, y)\n",
    "            hyps.extend(pred)\n",
    "            refs.extend(labels)\n",
    "\n",
    "    results = [(preproc.decode(r), preproc.decode(h)) for r, h in zip(refs, hyps)]\n",
    "    \n",
    "    if store_prediction:\n",
    "        with open(\"test_results.json\", \"w\") as res:\n",
    "            json.dump(results, res)\n",
    "\n",
    "    if print_prediction:\n",
    "        for (truth, pred) in results:\n",
    "            print('True label:\\n  ', end=\"\")\n",
    "            for char in truth:\n",
    "                print(char, end=\" \")\n",
    "            print('\\nPredicted labal:\\n  ', end=\"\")\n",
    "            for char in pred:\n",
    "                print(char, end=\" \")\n",
    "            print('')\n",
    "\n",
    "    return np.nanmean(losses), compute_wer(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing finished 23.47907018661499 seconds elapsed\n",
      "Train Loaded 2349.8854501247406 seconds elapsed\n",
      "Dev Loaded 233.77835059165955 seconds elapsed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'nei3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6e64a470f3d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mtest_ldr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_cfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_set\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_cfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Loaded\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"seconds elapsed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TTIC-31110-Final-Project\\rnn\\loader.py\u001b[0m in \u001b[0;36mmake_loader\u001b[1;34m(dataset_json, preproc, batch_size)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[0mcollate_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TTIC-31110-Final-Project\\rnn\\loader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_json, preproc, batch_size)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpreproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"audio\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_data_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TTIC-31110-Final-Project\\rnn\\loader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpreproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"audio\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_data_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TTIC-31110-Final-Project\\rnn\\loader.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(self, wav, text)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TTIC-31110-Final-Project\\rnn\\loader.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTART\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;31m#print([self.char_to_int[t] for t in text])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar_to_int\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TTIC-31110-Final-Project\\rnn\\loader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTART\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;31m#print([self.char_to_int[t] for t in text])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar_to_int\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'nei3'"
     ]
    }
   ],
   "source": [
    "#Loading\n",
    "\n",
    "with open(\"rnn/config.json\", \"r\") as fid:                                                                                                                                                                                                                                      \n",
    "    config = json.load(fid)\n",
    "\n",
    "data_cfg = config[\"data\"]\n",
    "model_cfg = config[\"model\"]\n",
    "opt_cfg = config[\"optimizer\"]\n",
    "\n",
    "start = time.time()\n",
    "preproc = Preprocessor(data_cfg[\"train_set\"], start_and_end=data_cfg[\"start_and_end\"])\n",
    "print(\"Preprocessing finished\", time.time() - start, \"seconds elapsed\")\n",
    "\n",
    "start = time.time()\n",
    "train_ldr = make_loader(data_cfg[\"train_set\"], preproc, opt_cfg[\"batch_size\"])\n",
    "print(\"Train Loaded\", time.time() - start, \"seconds elapsed\")   \n",
    "\n",
    "start = time.time()    \n",
    "dev_ldr = make_loader(data_cfg[\"dev_set\"], preproc, opt_cfg[\"batch_size\"])\n",
    "print(\"Dev Loaded\", time.time() - start, \"seconds elapsed\")\n",
    "\n",
    "start = time.time()\n",
    "test_ldr = make_loader(data_cfg[\"test_set\"], preproc, opt_cfg[\"batch_size\"])\n",
    "print(\"Test Loaded\", time.time() - start, \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(\"Training RNN\")\n",
    "print(\"------------\")\n",
    "\n",
    "attention = Attention(model_cfg[\"encoder\"][\"hidden_size\"], model_cfg[\"decoder\"][\"hidden_size\"], 64)\n",
    "model = Seq2Seq(preproc.input_dim, preproc.vocab_size, attention, model_cfg)\n",
    "model = model.cuda() if use_cuda else model.cpu()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=opt_cfg[\"learning_rate\"], momentum=opt_cfg[\"momentum\"])\n",
    "#change this\n",
    "mslst = [int(y) for y in [25 * x for x in range(1,20)] if y < opt_cfg[\"max_epochs\"]]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=mslst, gamma=0.1)\n",
    "\n",
    "log=\"epoch {:4} | train_loss={:6.2f}, dev_loss={:6.2f} with {:6.2f}% WER ({:6.2f}s elapsed)\"\n",
    "losses = []\n",
    "weres = []\n",
    "eps = list(range(opt_cfg[\"max_epochs\"]))\n",
    "\n",
    "best_so_far = float(\"inf\")\n",
    "for ep in range(opt_cfg[\"max_epochs\"]):\n",
    "    start = time.time()\n",
    "    scheduler.step()\n",
    "\n",
    "    train_loss = train(model, optimizer, train_ldr)    \n",
    "    dev_loss, dev_wer = evaluate(model, dev_ldr, preproc)    \n",
    "    losses.append(dev_loss)\n",
    "    weres.append(dev_wer)\n",
    "    \n",
    "    print(log.format(ep + 1, train_loss, dev_loss, dev_wer * 100., time.time() - start))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print('...learning rate: ' + str(param_group['lr']))\n",
    "\n",
    "    torch.save(model, os.path.join(config[\"save_path\"], str(ep)))   \n",
    "    if dev_wer < best_so_far:\n",
    "        best_so_far = dev_wer\n",
    "        torch.save(model, os.path.join(config[\"save_path\"], \"best\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "plt.suptitle(\"Loss & WER v.s. Time\", fontsize=14)\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(eps, losses, 'green')\n",
    "ax2.plot(eps, weres, 'blue')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss', color='green')\n",
    "ax2.set_ylabel('WER', color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "print(\"Testing RNN\")\n",
    "print(\"-------------\")\n",
    "\n",
    "test_model = torch.load(os.path.join(config[\"save_path\"], \"best\"))\n",
    "_, test_wer = evaluate(test_model, test_ldr, preproc, store_prediction=True, print_prediction=True)\n",
    "\n",
    "print(\"{:.2f}% WER (test)\".format(test_wer * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
