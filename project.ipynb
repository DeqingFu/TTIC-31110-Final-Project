{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'invalid': 'warn', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import editdistance\n",
    "import os\n",
    "import glob\n",
    "from rnn.loader import make_loader, Preprocessor\n",
    "from rnn.model import Seq2Seq\n",
    "from rnn.model import LinearND \n",
    "from rnn.model import Attention\n",
    "import matplotlib.pyplot as plt\n",
    "np.seterr(divide='ignore') # masks log(0) errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wer(results):\n",
    "    \"\"\"\n",
    "    Compute the word-error-rate (WER).\n",
    "    \"\"\"\n",
    "    dist = 0.\n",
    "    for label, pred in results:\n",
    "        dist += editdistance.eval(label, pred)\n",
    "    total = sum(len(label) for label, _ in results)\n",
    "    return dist / total\n",
    "\n",
    "def train(model, optimizer, ldr):\n",
    "    \"\"\"\n",
    "    Train the model for an epoch (one pass over the training data)\n",
    "    ----\n",
    "    model: Seq2Seq model instance\n",
    "    optimizer: torch.nn optimizer instance\n",
    "    ldr: data loader instance\n",
    "    ----\n",
    "    Returns the average loss over an epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    model.scheduled_sampling = model.sample_prob != 0\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for ii, (inputs, labels) in enumerate(ldr):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = model.collate(inputs, labels)\n",
    "        loss = model.loss(x, y)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())\n",
    "        \n",
    "    return np.nanmean(losses)\n",
    "\n",
    "def evaluate(model, ldr, preproc, store_prediction=False, print_prediction=False):\n",
    "    \"\"\"\n",
    "    Evaluate the model (on either dev or test).\n",
    "    ----\n",
    "    model: Seq2Seq model instance\n",
    "    ldr: data loader instance\n",
    "    preproc: preprocessor instance\n",
    "    ----\n",
    "    Returns the average loss and wer on a given dataset\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.scheduled_sampling = False\n",
    "    \n",
    "    losses, hyps, refs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in ldr:\n",
    "            x, y = model.collate(inputs, labels)\n",
    "            # get loss\n",
    "            loss = model.loss(x, y)\n",
    "            losses.append(loss.data.item())\n",
    "            # get predictions\n",
    "            pred = model.infer(x, y)\n",
    "            hyps.extend(pred)\n",
    "            refs.extend(labels)\n",
    "\n",
    "    results = [(preproc.decode(r), preproc.decode(h)) for r, h in zip(refs, hyps)]\n",
    "    \n",
    "    if store_prediction:\n",
    "        with open(\"test_results.json\", \"w\") as res:\n",
    "            json.dump(results, res)\n",
    "\n",
    "    if print_prediction:\n",
    "        for (truth, pred) in results:\n",
    "            print('True label:\\n  ', end=\"\")\n",
    "            for char in truth:\n",
    "                print(char, end=\" \")\n",
    "            print('\\nPredicted labal:\\n  ', end=\"\")\n",
    "            for char in pred:\n",
    "                print(char, end=\" \")\n",
    "            print('')\n",
    "\n",
    "    return np.nanmean(losses), compute_wer(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing finished 26.85626196861267 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "#Loading\n",
    "\n",
    "with open(\"rnn/config.json\", \"r\") as fid:                                                                                                                                                                                                                                      \n",
    "    config = json.load(fid)\n",
    "\n",
    "data_cfg = config[\"data\"]\n",
    "opt_cfg = config[\"optimizer\"]\n",
    "\n",
    "start = time.time()\n",
    "preproc = Preprocessor(data_cfg[\"all_data\"], start_and_end=data_cfg[\"start_and_end\"])\n",
    "print(\"Preprocessing finished\", time.time() - start, \"seconds elapsed\")\n",
    "\n",
    "start = time.time()\n",
    "train_ldr = make_loader(data_cfg[\"train_set\"], preproc, opt_cfg[\"batch_size\"])\n",
    "print(\"Train Loaded\", time.time() - start, \"seconds elapsed\")   \n",
    "\n",
    "start = time.time()    \n",
    "dev_ldr = make_loader(data_cfg[\"dev_set\"], preproc, opt_cfg[\"batch_size\"])\n",
    "print(\"Dev Loaded\", time.time() - start, \"seconds elapsed\")\n",
    "\n",
    "start = time.time()\n",
    "test_ldr = make_loader(data_cfg[\"test_set\"], preproc, opt_cfg[\"batch_size\"])\n",
    "print(\"Test Loaded\", time.time() - start, \"seconds elapsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "# Reload config if changed epoch\n",
    "with open(\"rnn/config.json\", \"r\") as fid:                                                                                                                                                                                                                                      \n",
    "    config = json.load(fid)\n",
    "model_cfg = config[\"model\"]\n",
    "opt_cfg = config[\"optimizer\"]\n",
    "print(\"max epochs:\", opt_cfg[\"max_epochs\"])\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(\"Training RNN\")\n",
    "print(\"------------\")\n",
    "\n",
    "attention = Attention(model_cfg[\"encoder\"][\"hidden_size\"], model_cfg[\"decoder\"][\"hidden_size\"], 64)\n",
    "model = Seq2Seq(preproc.input_dim, preproc.vocab_size, attention, model_cfg)\n",
    "model = model.cuda() if use_cuda else model.cpu()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=opt_cfg[\"learning_rate\"], momentum=opt_cfg[\"momentum\"])\n",
    "#change this\n",
    "mslst = [int(y) for y in [25 * (4 ** x) for x in range(20)] if y < opt_cfg[\"max_epochs\"]]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=mslst, gamma=0.1)\n",
    "\n",
    "log=\"epoch {:4} | train_loss={:6.2f}, dev_loss={:6.2f} with {:6.2f}% WER ({:6.2f}s elapsed)\"\n",
    "losses = []\n",
    "weres = []\n",
    "eps = list(range(opt_cfg[\"max_epochs\"]))\n",
    "\n",
    "best_so_far = float(\"inf\")\n",
    "for ep in range(opt_cfg[\"max_epochs\"]):\n",
    "    start = time.time()\n",
    "    scheduler.step()\n",
    "\n",
    "    train_loss = train(model, optimizer, train_ldr)    \n",
    "    dev_loss, dev_wer = evaluate(model, dev_ldr, preproc)    \n",
    "    losses.append(dev_loss)\n",
    "    weres.append(dev_wer)\n",
    "    \n",
    "    print(log.format(ep + 1, train_loss, dev_loss, dev_wer * 100., time.time() - start))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print('...learning rate: ' + str(param_group['lr']))\n",
    "\n",
    "    torch.save(model, os.path.join(config[\"save_path\"], str(ep)))   \n",
    "    if dev_wer < best_so_far:\n",
    "        best_so_far = dev_wer\n",
    "        torch.save(model, os.path.join(config[\"save_path\"], \"best\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "plt.suptitle(\"Loss & WER v.s. Time\", fontsize=14)\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(eps, losses, 'green')\n",
    "ax2.plot(eps, weres, 'blue')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss', color='green')\n",
    "ax2.set_ylabel('WER', color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "print(\"Testing RNN\")\n",
    "print(\"-------------\")\n",
    "\n",
    "test_model = torch.load(os.path.join(config[\"save_path\"], \"best\"))\n",
    "_, test_wer = evaluate(model, test_ldr, preproc, store_prediction=True, print_prediction=True)\n",
    "\n",
    "print(\"{:.2f}% WER (test)\".format(test_wer * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
